{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# ==========================================================\n# ðŸŒ¾ AgroScan â€“ Crop Disease Classification using CNN\n# ==========================================================\n\nimport os\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential, Model\nfrom tensorflow.keras.layers import (Conv2D, DepthwiseConv2D, BatchNormalization,\n                                     ReLU, Dropout, Dense, GlobalAveragePooling2D)\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom sklearn.metrics import confusion_matrix, classification_report\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport cv2\nimport random\n\ntf.random.set_seed(42)\nnp.random.seed(42)\nrandom.seed(42)\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"IMG_SIZE = (224, 224)\nBATCH_SIZE = 32\nEPOCHS = 40\nNUM_CLASSES = 38  # PlantVillage has 38 disease categories\n\nTRAIN_DIR = \"data/train\"\nVAL_DIR   = \"data/val\"\nTEST_DIR  = \"data/test\"\n\nos.makedirs(\"results/gradcam_examples\", exist_ok=True)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_datagen = ImageDataGenerator(\n    rescale=1./255,\n    rotation_range=25,\n    width_shift_range=0.15,\n    height_shift_range=0.15,\n    zoom_range=0.15,\n    horizontal_flip=True,\n    brightness_range=[0.7,1.3]\n)\nval_datagen = ImageDataGenerator(rescale=1./255)\ntest_datagen = ImageDataGenerator(rescale=1./255)\n\ntrain_gen = train_datagen.flow_from_directory(TRAIN_DIR, target_size=IMG_SIZE, batch_size=BATCH_SIZE, class_mode='categorical')\nval_gen = val_datagen.flow_from_directory(VAL_DIR, target_size=IMG_SIZE, batch_size=BATCH_SIZE, class_mode='categorical', shuffle=False)\ntest_gen = test_datagen.flow_from_directory(TEST_DIR, target_size=IMG_SIZE, batch_size=BATCH_SIZE, class_mode='categorical', shuffle=False)\n\nprint(\"âœ… Classes:\", len(train_gen.class_indices))\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model = Sequential([\n    Conv2D(64, (3,3), activation='relu', padding='same', input_shape=(224,224,3)),\n    BatchNormalization(),\n    MaxPooling2D(2,2),\n\n    Conv2D(128, (3,3), activation='relu', padding='same'),\n    BatchNormalization(),\n    MaxPooling2D(2,2),\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import (Input, Conv2D, MaxPooling2D, BatchNormalization,\n                                     Dropout, GlobalAveragePooling2D, Dense)\nfrom tensorflow.keras.regularizers import l2\n\ninputs = Input(shape=(224,224,3))\n\n# Block 1\nx = Conv2D(32, (3,3), activation='relu', padding='same', kernel_regularizer=l2(0.001))(inputs)\nx = BatchNormalization()(x)\nx = Conv2D(32, (3,3), activation='relu', padding='same', kernel_regularizer=l2(0.001))(x)\nx = BatchNormalization()(x)\nx = MaxPooling2D(2,2)(x)\nx = Dropout(0.25)(x)\n\n# Block 2\nx = Conv2D(64, (3,3), activation='relu', padding='same', kernel_regularizer=l2(0.001))(x)\nx = BatchNormalization()(x)\nx = Conv2D(64, (3,3), activation='relu', padding='same', kernel_regularizer=l2(0.001))(x)\nx = BatchNormalization()(x)\nx = MaxPooling2D(2,2)(x)\nx = Dropout(0.3)(x)\n\n# Block 3\nx = Conv2D(128, (3,3), activation='relu', padding='same', kernel_regularizer=l2(0.001))(x)\nx = BatchNormalization()(x)\nx = Conv2D(128, (3,3), activation='relu', padding='same', kernel_regularizer=l2(0.001))(x)\nx = BatchNormalization()(x)\nx = MaxPooling2D(2,2)(x)\nx = Dropout(0.35)(x)\n\n# Block 4\nx = Conv2D(256, (3,3), activation='relu', padding='same', kernel_regularizer=l2(0.001))(x)\nx = BatchNormalization()(x)\nx = Conv2D(256, (3,3), activation='relu', padding='same', kernel_regularizer=l2(0.001))(x)\nx = BatchNormalization()(x)\nx = MaxPooling2D(2,2)(x)\nx = Dropout(0.4)(x)\n\n# Classification Head\nx = GlobalAveragePooling2D()(x)\nx = Dense(512, activation='relu', kernel_regularizer=l2(0.001))(x)\nx = Dropout(0.5)(x)\noutputs = Dense(NUM_CLASSES, activation='softmax')(x)\n\nmodel = Model(inputs, outputs)\nmodel.summary()\n\n    Conv2D(256, (3,3), activation='relu', padding='same'),\n    BatchNormalization(),\n    Dropout(0.3),\n    GlobalAveragePooling2D(),\n\n    Dense(128, activation='relu'),\n    Dropout(0.4),\n    Dense(NUM_CLASSES, activation='softmax')\n])\n\nmodel.compile(optimizer=tf.keras.optimizers.Adam(1e-4),\n              loss='categorical_crossentropy',\n              metrics=['accuracy'])\n\nmodel.summary()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.compile(optimizer=tf.keras.optimizers.Adam(1e-3),\n              loss='categorical_crossentropy',\n              metrics=['accuracy'])\n\ncallbacks = [\n    EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True),\n    ModelCheckpoint(\"results/best_model.h5\", monitor='val_accuracy', save_best_only=True)\n]\n\nhistory = model.fit(train_gen, validation_data=val_gen, epochs=EPOCHS, callbacks=callbacks)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.figure(figsize=(10,4))\nplt.subplot(1,2,1)\nplt.plot(history.history['accuracy'], label='Train Acc')\nplt.plot(history.history['val_accuracy'], label='Val Acc')\nplt.legend(); plt.title('Accuracy')\n\nplt.subplot(1,2,2)\nplt.plot(history.history['loss'], label='Train Loss')\nplt.plot(history.history['val_loss'], label='Val Loss')\nplt.legend(); plt.title('Loss')\n\nplt.tight_layout()\nplt.savefig(\"results/training_curves.png\")\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"val_loss, val_acc = model.evaluate(val_gen)\nprint(f\"Validation Accuracy: {val_acc*100:.2f}%\")\n\npreds = model.predict(val_gen)\ny_pred = np.argmax(preds, axis=1)\ny_true = val_gen.classes\n\nprint(classification_report(y_true, y_pred))\n\ncm = confusion_matrix(y_true, y_pred)\nplt.figure(figsize=(8,7))\nsns.heatmap(cm, cmap='Greens', fmt='d')\nplt.title('Confusion Matrix')\nplt.savefig(\"results/confusion_matrix.png\")\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def generate_gradcam(img_path, model, layer_name):\n    img = cv2.imread(img_path)\n    img = cv2.resize(img, IMG_SIZE)\n    x = np.expand_dims(img/255.0, axis=0)\n    grad_model = Model(inputs=model.inputs, outputs=[model.get_layer(layer_name).output, model.output])\n    with tf.GradientTape() as tape:\n        conv_out, preds = grad_model(x)\n        class_idx = tf.argmax(preds[0])\n        loss = preds[:, class_idx]\n    grads = tape.gradient(loss, conv_out)[0]\n    weights = tf.reduce_mean(grads, axis=(0,1))\n    cam = np.maximum(np.sum(weights * conv_out[0], axis=-1), 0)\n    cam = cv2.resize(cam.numpy(), IMG_SIZE)\n    cam = cam / cam.max()\n    return cam, int(class_idx)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sample_class = list(test_gen.class_indices.keys())[0]\nsample_img = os.path.join(TEST_DIR, sample_class, os.listdir(os.path.join(TEST_DIR, sample_class))[0])\n\nheatmap, cls = generate_gradcam(sample_img, model, layer_name='conv2d_3')\n\norig = cv2.imread(sample_img)\norig = cv2.resize(orig, IMG_SIZE)\ncolored = cv2.applyColorMap(np.uint8(255*heatmap), cv2.COLORMAP_JET)\nsuperimposed = cv2.addWeighted(orig, 0.6, colored, 0.4, 0)\ncv2.imwrite(\"results/gradcam_examples/sample_leaf.jpg\", superimposed)\nplt.imshow(cv2.cvtColor(superimposed, cv2.COLOR_BGR2RGB))\nplt.title(f\"Grad-CAM Heatmap â€“ Predicted Class {cls}\")\nplt.axis('off')\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}