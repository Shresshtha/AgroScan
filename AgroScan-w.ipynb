{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# ==========================================================\n",
    "# ðŸŒ¾ AgroScan â€“ Crop Disease Classification using CNN\n",
    "# ==========================================================\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import (Conv2D, DepthwiseConv2D, BatchNormalization,\n",
    "                                     ReLU, Dropout, Dense, GlobalAveragePooling2D)\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "import random\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = (224, 224)\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 40\n",
    "NUM_CLASSES = 38  # PlantVillage has 38 disease categories\n",
    "\n",
    "TRAIN_DIR = \"data/train\"\n",
    "VAL_DIR   = \"data/val\"\n",
    "TEST_DIR  = \"data/test\"\n",
    "\n",
    "os.makedirs(\"results/gradcam_examples\", exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=25,\n",
    "    width_shift_range=0.15,\n",
    "    height_shift_range=0.15,\n",
    "    zoom_range=0.15,\n",
    "    horizontal_flip=True,\n",
    "    brightness_range=[0.7,1.3]\n",
    ")\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_gen = train_datagen.flow_from_directory(TRAIN_DIR, target_size=IMG_SIZE, batch_size=BATCH_SIZE, class_mode='categorical')\n",
    "val_gen = val_datagen.flow_from_directory(VAL_DIR, target_size=IMG_SIZE, batch_size=BATCH_SIZE, class_mode='categorical', shuffle=False)\n",
    "test_gen = test_datagen.flow_from_directory(TEST_DIR, target_size=IMG_SIZE, batch_size=BATCH_SIZE, class_mode='categorical', shuffle=False)\n",
    "\n",
    "print(\"âœ… Classes:\", len(train_gen.class_indices))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained MobileNetV2\n",
    "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Add custom classification head\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "predictions = Dense(38, activation='softmax')(x)\n",
    "\n",
    "# Create model\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Freeze base model layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Compile model\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(1e-3),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True),\n",
    "    ModelCheckpoint(\"results/best_model.h5\", monitor='val_accuracy', save_best_only=True)\n",
    "]\n",
    "\n",
    "history = model.fit(train_gen, validation_data=val_gen, epochs=EPOCHS, callbacks=callbacks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,4))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(history.history['accuracy'], label='Train Acc')\n",
    "plt.plot(history.history['val_accuracy'], label='Val Acc')\n",
    "plt.legend(); plt.title('Accuracy')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Val Loss')\n",
    "plt.legend(); plt.title('Loss')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"results/training_curves.png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loss, val_acc = model.evaluate(val_gen)\n",
    "print(f\"Validation Accuracy: {val_acc*100:.2f}%\")\n",
    "\n",
    "preds = model.predict(val_gen)\n",
    "y_pred = np.argmax(preds, axis=1)\n",
    "y_true = val_gen.classes\n",
    "\n",
    "print(classification_report(y_true, y_pred))\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "plt.figure(figsize=(8,7))\n",
    "sns.heatmap(cm, cmap='Greens', fmt='d')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.savefig(\"results/confusion_matrix.png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_gradcam(img_path, model, layer_name):\n",
    "    img = cv2.imread(img_path)\n",
    "    img = cv2.resize(img, IMG_SIZE)\n",
    "    x = np.expand_dims(img/255.0, axis=0)\n",
    "    grad_model = Model(inputs=model.inputs, outputs=[model.get_layer(layer_name).output, model.output])\n",
    "    with tf.GradientTape() as tape:\n",
    "        conv_out, preds = grad_model(x)\n",
    "        class_idx = tf.argmax(preds[0])\n",
    "        loss = preds[:, class_idx]\n",
    "    grads = tape.gradient(loss, conv_out)[0]\n",
    "    weights = tf.reduce_mean(grads, axis=(0,1))\n",
    "    cam = np.maximum(np.sum(weights * conv_out[0], axis=-1), 0)\n",
    "    cam = cv2.resize(cam.numpy(), IMG_SIZE)\n",
    "    cam = cam / cam.max()\n",
    "    return cam, int(class_idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_class = list(test_gen.class_indices.keys())[0]\n",
    "sample_img = os.path.join(TEST_DIR, sample_class, os.listdir(os.path.join(TEST_DIR, sample_class))[0])\n",
    "\n",
    "heatmap, cls = generate_gradcam(sample_img, model, layer_name='conv2d_3')\n",
    "\n",
    "orig = cv2.imread(sample_img)\n",
    "orig = cv2.resize(orig, IMG_SIZE)\n",
    "colored = cv2.applyColorMap(np.uint8(255*heatmap), cv2.COLORMAP_JET)\n",
    "superimposed = cv2.addWeighted(orig, 0.6, colored, 0.4, 0)\n",
    "cv2.imwrite(\"results/gradcam_examples/sample_leaf.jpg\", superimposed)\n",
    "plt.imshow(cv2.cvtColor(superimposed, cv2.COLOR_BGR2RGB))\n",
    "plt.title(f\"Grad-CAM Heatmap â€“ Predicted Class {cls}\")\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
